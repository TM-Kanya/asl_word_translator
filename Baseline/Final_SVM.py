# -*- coding: utf-8 -*-
"""Another copy of v2_aps_svm_hog.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-LcbLkA3fQLjYOEpydj5nVRI1JhYmH_I
"""

import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from skimage.feature import hog
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, learning_curve
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from google.colab import drive
from multiprocessing import Pool
import json
import random
from tqdm import tqdm

def extract_frames(video_info):
    video_id, frame_rate, img_size = video_info
    video_path = os.path.join(video_folder, f'{video_id}.mp4')
    output_folder = os.path.join(data_path, 'processed_frames', video_id)

    if not os.path.exists(video_path):
        return None

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        return None

    os.makedirs(output_folder, exist_ok=True)
    frames = []
    frame_count = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        if frame_count % frame_rate == 0:
            frame = cv2.resize(frame, img_size)
            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Keep images in RGB format # cv2.COLOR_BGR2RGB
            frame_path = os.path.join(output_folder, f'frame_{frame_count}.jpg')
            cv2.imwrite(frame_path, frame)  # Save in correct format
            frames.append(frame)

        frame_count += 1

    cap.release()
    return (video_id, frames)

def extract_hog_features(frames):
  """
  Extracts HOG features from multiple grayscale frames and stacks them into a single feature vector.

  Args:
      video_path (str): Path to video file.
      num_frames (int): Number of frames to stack together.

  Returns:
      np.array: Stacked feature vector.
  """
  features = []

  output_folder = os.path.join(data_path, 'hog_frames')

  frame_count = 0
  for frame in frames:
    # Compute HOG features
    hog_features, hog_image = hog(frame, orientations=9, pixels_per_cell=(8, 8),
                          cells_per_block=(2, 2), visualize=True, feature_vector=True)

    features.append(hog_features)

    # plt.figure(figsize=(8, 4))
    # plt.subplot(1, 2, 1)
    # plt.imshow(frame, cmap='gray')
    # plt.title('Original Frame')

    # plt.subplot(1, 2, 2)
    # plt.imshow(hog_image, cmap='gray')
    # plt.title('HOG Features')
    # plt.savefig(f"hog_frame{frame_count}.png", bbox_inches='tight')
    # #plt.show()

    frame_count += 1

  # Stack all frame features into a single feature vector
  return np.mean(features, axis=0) if features else None

from google.colab import drive
drive.mount('/content/drive')

def prepare_dataset():
  # Load dataset metadata
  with open(json_file, 'r') as f:
      wlasl_data = json.load(f)

  video_infos = []
  gloss_data = []

  for entry in wlasl_data[:1000]:
    gloss = entry['gloss']
    for instance in entry['instances']:
      video_id = instance['video_id']
      video_infos.append((video_id, 5, (224, 224)))  # Extract every 5th frame

  with Pool(processes=4) as pool:
    extracted_data = list(tqdm(pool.imap(extract_frames, video_infos), total=len(video_infos), desc='Processing Videos'))

  X = []
  y = []

  for data in extracted_data:
    if data:
      video_id, frames = data
      gloss = next((entry['gloss'] for entry in wlasl_data if any(instance['video_id'] == video_id for instance in entry['instances'])), None)
      gloss_data.append({'gloss': gloss, 'video_id': video_id, 'frames': frames})

      ft_vector = extract_hog_features(frames)

      if ft_vector is not None:
        X.append(ft_vector)
        y.append(gloss)

  np.save("x.npy", np.stack(X, axis=0))
  np.save("y.npy", np.array(y))
  return np.stack(X, axis=0), np.array(y)

def SVM(X, y):
  # Encode labels as numbers
  encoder = LabelEncoder()
  y_encoded = encoder.fit_transform(y)

  # Split into train and test sets
  X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)

  # Train SVM (use balanced to avoid bias)
  svm = SVC(kernel="linear", probability=True, class_weight="balanced")
  svm.fit(X_train, y_train)

  # Evaluate Model
  y_pred = svm.predict(X_test)

  return X_train, y_train, X_test, y_test, y_pred, encoder, svm

from sklearn.utils.multiclass import unique_labels
def scores(y_test, y_pred, encoder):
    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    plt.figure(figsize=(12, 8))
    ax = sns.heatmap(cm, annot=True, fmt="d", cmap="RdPu",
                     xticklabels=encoder.classes_, yticklabels=encoder.classes_)
    plt.xticks(rotation=45, ha="right")
    plt.yticks(rotation=45, ha="right")
    plt.xlabel("Predicted Label/Word")
    plt.ylabel("True Label/Word")
    plt.title("Confusion Matrix for SVM-Based ASL Translation")
    plt.tight_layout()
    plt.savefig('ConfusionMatrix.png', bbox_inches='tight')
    plt.show()

    # Accuracy
    accuracy_string = f"Test Accuracy: {accuracy_score(y_test, y_pred) * 100:.2f}%\n"
    print(accuracy_string)

    # Ensure target names match the actual labels present in y_test
    valid_classes = unique_labels(y_test, y_pred)  # Extract only labels that appear in y_test/y_pred
    target_names = [encoder.classes_[i] for i in valid_classes]  # Get corresponding names

    # Classification Report
    classification_report_string = f"Classification Report:\n{classification_report(y_test, y_pred, target_names=target_names)}\n"
    print(classification_report_string)

    # Write scores to file
    with open("SVMScores.txt", "w") as f:
        f.write(accuracy_string)
        f.write(classification_report_string)

def scores1(y_test, y_pred, encoder):
    # Confusion Matrix
    cm = confusion_matrix(y_test[:10], y_pred[:10])
    plt.figure(figsize=(12, 8))
    ax = sns.heatmap(cm, annot=True, fmt="d", cmap="RdPu", xticklabels=encoder.classes_, yticklabels=encoder.classes_)
    plt.xticks(rotation=45, ha="right")
    plt.yticks(rotation=45, ha="right")
    plt.xlabel("Predicted Label/Word")
    plt.ylabel("True Label/Word")
    plt.title("Confusion Matrix for SVM-Based ASL Translation")
    plt.tight_layout()
    plt.savefig('ConfusionMatrix.png', bbox_inches='tight')
    plt.show()

    # Accuracy
    accuracy_string = f"Test Accuracy: {accuracy_score(y_test, y_pred) * 100}%\n"
    print(accuracy_string)

    # Get unique labels in y_test
    unique_labels = np.unique(y_test)

    # Classification Report - Use only the classes present in y_test
    classification_report_string = f"Classification Report:\n{classification_report(y_test, y_pred, target_names=encoder.classes_[unique_labels])}\n"
    print(classification_report_string)

    # Write scores to file
    with open("SVMScores.txt", "w") as f:
        f.write(accuracy_string)
        f.write(classification_report_string)

def learning_curve_plot(model, X, y):
    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=5, scoring="accuracy", train_sizes=np.linspace(0.1, 1.0, 5))

    train_accuracy = np.mean(train_scores, axis=1) * 100
    test_accuracy = np.mean(test_scores, axis=1) * 100

    plt.figure()
    plt.plot(train_sizes, train_accuracy, "o-", color="lightseagreen", label="Training Accuracy")
    plt.plot(train_sizes, test_accuracy, "o-", color="palevioletred", label="Validation Accuracy")
    plt.xlabel("Training Size")
    plt.ylabel("Accuracy (%)")
    plt.title("Learning Curve of Training Data")
    plt.legend()
    plt.savefig('LearningCurve.png', bbox_inches='tight')
    plt.show()

data_path = '/content/drive/MyDrive/WLASL_dataset'
video_folder = os.path.join(data_path, 'videos')
json_file = os.path.join(data_path, 'WLASL_v0.3.json')

drive.mount('/content/drive')

X, y = prepare_dataset()

np.save("x.npy", X)
np.save("y.npy", y)

X_train, y_train, X_test, y_test, y_pred, encoder, svm = SVM(X, y)
scores(y_test, y_pred, encoder)
learning_curve_plot(svm, X_train, y_train)
#find_misclassified_samples(X_test, y_test, y_pred, encoder)

scores(y_test[:1], y_pred[:1], encoder)

"""

```
def incorrect_predictions(y_test, y_pred, encoder, labels, frame_folder):
    incorrect_indices = np.where(y_test != y_pred)[0]
    
    print(f"Total Misclassified Samples: {len(misclassified_indices)}")
    
    if len(misclassified_indices) == 0:
        print("No misclassified samples found.")
        return
    
    # Show only the first 3 incorrect words
    num_samples = 3
    plt.figure(figsize=(10, num_samples * 3))

    for i, idx in enumerate(misclassified_indices[:num_samples]):
        true_label = encoder.inverse_transform([y_test[idx]])[0]
        predicted_label = encoder.inverse_transform([y_pred[idx]])[0]
        
        # Find the folder that contains frames for this sample
        video_folders = os.listdir(frame_folder)
        video_folder = next((f for f in video_folders if labels.get(f) == true_label), None)

        if video_folder:
            folder_path = os.path.join(frame_folder, video_folder)
            frame_files = sorted(os.listdir(folder_path))
            
            if frame_files:
                mid_idx = len(frame_files) // 2  # Select middle frame
                frame_path = os.path.join(folder_path, frame_files[mid_idx])
                
                frame = cv2.imread(frame_path)

                # Plot True Label
                plt.subplot(num_samples, 2, i * 2 + 1)
                plt.imshow(frame)
                plt.title(f"True: {true_label}", color="forestgreen")
                plt.axis("off")

                # Plot Predicted Label
                plt.subplot(num_samples, 2, i * 2 + 2)
                plt.imshow(frame)
                plt.title(f"Predicted: {predicted_label}", color="crimson")
                plt.axis("off")
            else:
                print(f"WARNING: No frames found in {folder_path}.")
        else:
            print(f"WARNING: No matching folder for {true_label}.")

    plt.tight_layout()
    plt.savefig('IncorrectWords.png', bbox_inches='tight')
    plt.show()

  f = open("SVMIncorrectWords.txt", "w")
  f.write(f"Number of Incorrect Predictions: {len(incorrect_indices)}\n")
  f.close()```

"""