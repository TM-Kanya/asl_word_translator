{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHVGwot9JKN-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "data_path = '/content/drive/MyDrive/WLASL_dataset'\n",
        "video_folder = os.path.join(data_path, 'videos')\n",
        "json_file = os.path.join(data_path, 'WLASL_v0.3.json')\n",
        "\n",
        "#load in the dataset\n",
        "with open(json_file,'r') as file_object:\n",
        "    wlasl_data = json.load(file_object)\n",
        "\n",
        "def extract_frames(img):\n",
        "    video_id, frame_rate, img_size = img\n",
        "    video_path = os.path.join(video_folder, f'{video_id}.mp4')\n",
        "    if not os.path.exists(video_path):\n",
        "        return None\n",
        "    #use opencv for file extractiong: https://www.geeksforgeeks.org/python-program-extract-frames-using-opencv/\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        return None\n",
        "    frames = []\n",
        "    frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        ret1, frame = cap.read()\n",
        "        if not ret1:\n",
        "            break\n",
        "        if (frame_count%frame_rate==0):\n",
        "            frame = cv2.resize(frame, img_size)\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # convert to grayscale\n",
        "            frames.append(frame)\n",
        "        frame_count+=1\n",
        "    cap.release()\n",
        "    return video_id, frames\n",
        "\n",
        "def create_transparent_layered_image(frames):\n",
        "    if not frames:\n",
        "        return None\n",
        "    layered_image = np.zeros_like(frames[0], dtype=np.float32)\n",
        "    #go through frames\n",
        "    for frame in frames:\n",
        "        layered_image += frame.astype(np.float32) * (1.0/len(frames)) #creating transparency per frame\n",
        "    layered_image = np.clip(layered_image,0,255).astype(np.uint8)\n",
        "    return layered_image\n",
        "\n",
        "def save_images(img, output_to='/content/drive/MyDrive/images'):\n",
        "    os.makedirs(output_to, exist_ok=True)\n",
        "    for i, data in enumerate(img):\n",
        "        gloss = data['gloss']\n",
        "        motion_image = data['motion_image']\n",
        "        gloss_folder = os.path.join(output_to, gloss)\n",
        "\n",
        "        os.makedirs(gloss_folder, exist_ok=True)\n",
        "        layered_filename = os.path.join(gloss_folder, f'layered_image_{i}.jpg')\n",
        "        try:\n",
        "            # saving grayscale image\n",
        "            cv2.imwrite(layered_filename, motion_image)\n",
        "            print(f\"Saved transparency layered image for gloss: {gloss} at {layered_filename}\")\n",
        "        except Exception as e:\n",
        "            print(f\"save failed\")\n",
        "\n",
        "def process(image_to_save):\n",
        "    gloss = image_to_save['gloss']\n",
        "    full_set = []\n",
        "    for instance in image_to_save['instances']:\n",
        "        full_set.append((instance['video_id'],2,(224, 224)))\n",
        "    images_to_save = []\n",
        "    for img in full_set:\n",
        "        data = extract_frames(img)\n",
        "        if data:\n",
        "            video_id, frames = data\n",
        "            motion_image = create_transparent_layered_image(frames) #apply pre-process\n",
        "            images_to_save.append({'gloss': gloss, 'video_id': video_id, 'frames': frames, 'motion_image': motion_image})\n",
        "\n",
        "    return images_to_save\n",
        "\n",
        "#to process them\n",
        "images_to_save = []\n",
        "for image_to_save in wlasl_data[:1000]:  #number of glosses processed\n",
        "    images_to_save.extend(process(image_to_save)) #process\n",
        "save_images(images_to_save) #save the image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  #referenced: https://pytorch.org/vision/0.9/transforms.html\n",
        "  augtransform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # Optional, depending on the task\n",
        "    transforms.RandomRotation(10),      # Optional, depending on the task\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Usually necessary\n",
        "])\n",
        "  augtransform2 = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomRotation(10),transforms.RandomAffine(10, translate=(0.1, 0.1)),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2),transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])"
      ],
      "metadata": {
        "id": "oyoK55NQZ_fE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}